from TagChecker.TagChecker import tag_checker

def tokenizer(html):
    list_of_tokens = list()
    start_symbol = "<"
    end_symbol = ">"
    token = ""
    is_token = False

    for char in html:
        if char == start_symbol:
            is_token = True
        elif char == end_symbol:
            token += char
            is_token = False
            list_of_tokens.append(token)
            token = ""
        if is_token:
            token += char

    isValid = True
    for token in list_of_tokens:
        if tag_checker(token) == False:
            isValid = False
            break

    if isValid:
        return list_of_tokens
    else:
        print("""
        ░██████╗██╗░░░██╗███╗░░██╗████████╗░█████╗░██╗░░██╗  ███████╗██████╗░██████╗░░█████╗░██████╗░
        ██╔════╝╚██╗░██╔╝████╗░██║╚══██╔══╝██╔══██╗╚██╗██╔╝  ██╔════╝██╔══██╗██╔══██╗██╔══██╗██╔══██╗
        ╚█████╗░░╚████╔╝░██╔██╗██║░░░██║░░░███████║░╚███╔╝░  █████╗░░██████╔╝██████╔╝██║░░██║██████╔╝
        ░╚═══██╗░░╚██╔╝░░██║╚████║░░░██║░░░██╔══██║░██╔██╗░  ██╔══╝░░██╔══██╗██╔══██╗██║░░██║██╔══██╗
        ██████╔╝░░░██║░░░██║░╚███║░░░██║░░░██║░░██║██╔╝╚██╗  ███████╗██║░░██║██║░░██║╚█████╔╝██║░░██║
        ╚═════╝░░░░╚═╝░░░╚═╝░░╚══╝░░░╚═╝░░░╚═╝░░╚═╝╚═╝░░╚═╝  ╚══════╝╚═╝░░╚═╝╚═╝░░╚═╝░╚════╝░╚═╝░░╚═╝""")
        print(f"Invalid Token: {token}")
        exit(1)
